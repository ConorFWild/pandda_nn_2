{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import configparser\n",
    "import pathlib as p\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clipper_python as clipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frag_nn.pytorch.network import GNINA_regressor, GNINA_regressor_v2, GNINA_regressor_v3, GNINA_regressor_v4, GNINA_regressor_v5, GNINA_regressor_v6, GNINA_regressor_v7, GNINA_regressor_v8\n",
    "from frag_nn.data import XChemData\n",
    "from frag_nn.pytorch.dataset import XChemDataset\n",
    "import frag_nn.constants as c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/dls/science/groups/i04-1/conor_dev/pandda_nn/frag_nn/params.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/dls/science/groups/i04-1/conor_dev/pandda_nn/frag_nn/params.ini']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.read(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_conf = conf[c.x_chem_database]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 48\n",
    "grid_step = 0.5\n",
    "network_version = 8\n",
    "dataset_version = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chem_dataset = XChemData(host=ds_conf[c.db_host], \n",
    "                         port=ds_conf[c.db_port], \n",
    "                         database=ds_conf[c.db_database], \n",
    "                         user=ds_conf[c.db_user], \n",
    "                         password=ds_conf[c.db_password])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = x_chem_dataset.get_database(\"pandda_event\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get accessible events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessible_events_list = []\n",
    "\n",
    "for pth in events[\"pandda_input_mtz\"]:\n",
    "    try:\n",
    "        if p.Path(pth).exists():\n",
    "            accessible_events_list.append(True)\n",
    "        else:\n",
    "            accessible_events_list.append(False)\n",
    "            \n",
    "    except PermissionError as e:\n",
    "        accessible_events_list.append(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessible_events_mask = np.array(accessible_events_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessible_events = events[accessible_events_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = np.random.rand(len(accessible_events)) < 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1691\n"
     ]
    }
   ],
   "source": [
    "events_train = accessible_events[split]#\n",
    "print(len(events_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "events_test = accessible_events[~split]\n",
    "print(len(events_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "events_train = pd.read_csv(\"new_events_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_test = pd.read_csv(\"new_events_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = XChemDataset(events_train,\n",
    "                              mode=\"RefMovev2\",\n",
    "                 grid_size=grid_size,\n",
    "                 grid_step=grid_step,\n",
    "                            replace_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = XChemDataset(events_test,\n",
    "                             mode=\"RefMovev2\",\n",
    "                 grid_size=grid_size,\n",
    "                 grid_step=grid_step,\n",
    "                           replace_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = dataset_train[10][\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_2 = dataset_train[10][\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_np_slice_2d = x[:, :, int(x.shape[2]/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_np_slice_2d_2 = x_2[:, :, int(x.shape[2]/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_np_slice_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_np_slice_2d_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                         batch_size=10, \n",
    "                                         shuffle=True,\n",
    "                                         num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                         batch_size=10, \n",
    "                                         shuffle=True,\n",
    "                                         num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6912\n"
     ]
    }
   ],
   "source": [
    "model = GNINA_regressor_v8(32,\n",
    "                        grid_dimension=grid_size,\n",
    "                          do_drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model_params_{}_{}_{}_{}.pt\".format(grid_size,\n",
    "                                                             grid_step,\n",
    "                                                                  network_version,\n",
    "                                                                     dataset_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNINA_regressor_v8(\n",
      "  (conv_1): Sequential(\n",
      "    (0): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer_1): ResidualLayerWithDropx2(\n",
      "    (conv_1): Sequential(\n",
      "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (res_1): ResidualBlock(\n",
      "      (conv_1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (res_2): ResidualBlock(\n",
      "      (conv_1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (res_3): ResidualBlock(\n",
      "      (conv_1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (drop): Dropout3d(p=0.1)\n",
      "    (mp): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (layer_2): ResidualLayerWithDropx2(\n",
      "    (conv_1): Sequential(\n",
      "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (res_1): ResidualBlock(\n",
      "      (conv_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (res_2): ResidualBlock(\n",
      "      (conv_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (res_3): ResidualBlock(\n",
      "      (conv_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (drop): Dropout3d(p=0.1)\n",
      "    (mp): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (layer_3): ResidualLayerWithDropx2(\n",
      "    (conv_1): Sequential(\n",
      "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (res_1): ResidualBlock(\n",
      "      (conv_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (res_2): ResidualBlock(\n",
      "      (conv_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (res_3): ResidualBlock(\n",
      "      (conv_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (drop): Dropout3d(p=0.1)\n",
      "    (mp): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=6912, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision - Recall functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(y_hat, y, cutoff):\n",
    "    \n",
    "    positives_hat_mask = (y_hat > cutoff)\n",
    "    negatives_hat_mask = (y_hat <= cutoff)\n",
    "    \n",
    "    positives_mask = (y == 1)\n",
    "    negatives_mask = (y == 0)\n",
    "\n",
    "    true_positives = np.count_nonzero(positives_hat_mask[positives_mask])\n",
    "    false_positives = np.count_nonzero(positives_hat_mask[negatives_mask])\n",
    "    \n",
    "    total_predicted_positives = true_positives + false_positives\n",
    "    \n",
    "    if total_predicted_positives == 0:\n",
    "        return 1\n",
    "    \n",
    "    precision = true_positives / total_predicted_positives\n",
    "    \n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(y_hat, y, cutoff):\n",
    "    positives_hat_mask = (y_hat > cutoff)\n",
    "    negatives_hat_mask = (y_hat <= cutoff)\n",
    "\n",
    "    positives_mask = (y == 1)\n",
    "    negatives_mask = (y == 0)\n",
    "\n",
    "    true_positives = np.count_nonzero(positives_hat_mask[positives_mask])\n",
    "    false_negatives = np.count_nonzero(negatives_hat_mask[positives_mask])    \n",
    "\n",
    "    total_positives = (true_positives + false_negatives)\n",
    "    \n",
    "    if total_positives == 0:\n",
    "        return 0\n",
    "    \n",
    "    recall = true_positives / total_positives\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_test_hat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "Iteration: 10\n",
      "Iteration: 11\n",
      "Iteration: 12\n",
      "Iteration: 13\n",
      "Iteration: 14\n",
      "Iteration: 15\n",
      "Iteration: 16\n",
      "Iteration: 17\n",
      "Iteration: 18\n",
      "Iteration: 19\n",
      "Iteration: 20\n",
      "Iteration: 21\n",
      "Iteration: 22\n",
      "Iteration: 23\n",
      "Iteration: 24\n",
      "Iteration: 25\n",
      "Iteration: 26\n",
      "Iteration: 27\n",
      "Iteration: 28\n",
      "Iteration: 29\n",
      "Iteration: 30\n",
      "Iteration: 31\n",
      "Iteration: 32\n",
      "Iteration: 33\n",
      "Iteration: 34\n",
      "Iteration: 35\n",
      "Iteration: 36\n",
      "Iteration: 37\n",
      "Iteration: 38\n",
      "Iteration: 39\n",
      "Iteration: 40\n",
      "Iteration: 41\n",
      "Iteration: 42\n",
      "Iteration: 43\n",
      "Iteration: 44\n",
      "Iteration: 45\n",
      "Iteration: 46\n",
      "Iteration: 47\n",
      "Iteration: 48\n",
      "Iteration: 49\n",
      "Iteration: 50\n",
      "Iteration: 51\n",
      "Iteration: 52\n",
      "Iteration: 53\n",
      "Iteration: 54\n",
      "Iteration: 55\n",
      "Iteration: 56\n",
      "Iteration: 57\n",
      "Iteration: 58\n",
      "Iteration: 59\n",
      "Iteration: 60\n",
      "Iteration: 61\n",
      "Iteration: 62\n",
      "Iteration: 63\n",
      "Iteration: 64\n",
      "Iteration: 65\n",
      "Iteration: 66\n",
      "Iteration: 67\n",
      "Iteration: 68\n",
      "Iteration: 69\n",
      "Iteration: 70\n",
      "Iteration: 71\n",
      "Iteration: 72\n",
      "Iteration: 73\n",
      "Iteration: 74\n",
      "Iteration: 75\n",
      "Iteration: 76\n",
      "Iteration: 77\n",
      "Iteration: 78\n",
      "Iteration: 79\n",
      "Iteration: 80\n",
      "Iteration: 81\n",
      "Iteration: 82\n",
      "Iteration: 83\n",
      "Iteration: 84\n",
      "Iteration: 85\n",
      "Iteration: 86\n",
      "Iteration: 87\n",
      "Iteration: 88\n",
      "Iteration: 89\n",
      "Iteration: 90\n",
      "Iteration: 91\n",
      "Iteration: 92\n",
      "Iteration: 93\n",
      "Iteration: 94\n",
      "Iteration: 95\n",
      "Iteration: 96\n",
      "Iteration: 97\n",
      "Iteration: 98\n",
      "Iteration: 99\n",
      "Iteration: 100\n",
      "Iteration: 101\n",
      "Iteration: 102\n",
      "Iteration: 103\n",
      "Iteration: 104\n",
      "Iteration: 105\n",
      "Iteration: 106\n",
      "Iteration: 107\n",
      "Iteration: 108\n",
      "Iteration: 109\n",
      "Iteration: 110\n",
      "Iteration: 111\n",
      "Iteration: 112\n",
      "Iteration: 113\n",
      "Iteration: 114\n",
      "Iteration: 115\n",
      "Iteration: 116\n",
      "Iteration: 117\n",
      "Iteration: 118\n",
      "Iteration: 119\n",
      "Iteration: 120\n",
      "Iteration: 121\n",
      "Iteration: 122\n",
      "Iteration: 123\n",
      "Iteration: 124\n",
      "Iteration: 125\n",
      "Iteration: 126\n",
      "Iteration: 127\n",
      "Iteration: 128\n",
      "Iteration: 129\n",
      "Iteration: 130\n",
      "Iteration: 131\n",
      "Iteration: 132\n",
      "Iteration: 133\n",
      "Iteration: 134\n",
      "Iteration: 135\n",
      "Iteration: 136\n",
      "Iteration: 137\n",
      "Iteration: 138\n",
      "Iteration: 139\n",
      "Iteration: 140\n",
      "Iteration: 141\n",
      "Iteration: 142\n",
      "Iteration: 143\n",
      "Iteration: 144\n",
      "Iteration: 145\n",
      "Iteration: 146\n",
      "Iteration: 147\n",
      "Iteration: 148\n",
      "Iteration: 149\n",
      "Iteration: 150\n",
      "Iteration: 151\n",
      "Iteration: 152\n",
      "Iteration: 153\n",
      "Iteration: 154\n",
      "Iteration: 155\n",
      "Iteration: 156\n",
      "Iteration: 157\n",
      "Iteration: 158\n",
      "Iteration: 159\n",
      "Iteration: 160\n",
      "Iteration: 161\n",
      "Iteration: 162\n",
      "Iteration: 163\n",
      "Iteration: 164\n",
      "Iteration: 165\n",
      "Iteration: 166\n",
      "Iteration: 167\n",
      "Iteration: 168\n",
      "Iteration: 169\n",
      "Iteration: 170\n",
      "Iteration: 171\n",
      "Iteration: 172\n",
      "Iteration: 173\n",
      "Iteration: 174\n",
      "Iteration: 175\n",
      "Iteration: 176\n",
      "Iteration: 177\n",
      "Iteration: 178\n",
      "Iteration: 179\n",
      "Iteration: 180\n",
      "Iteration: 181\n",
      "Iteration: 182\n",
      "Iteration: 183\n",
      "Iteration: 184\n",
      "Iteration: 185\n",
      "Iteration: 186\n",
      "Iteration: 187\n",
      "Iteration: 188\n",
      "Iteration: 189\n",
      "Iteration: 190\n",
      "Iteration: 191\n",
      "Iteration: 192\n",
      "Iteration: 193\n",
      "Iteration: 194\n",
      "Iteration: 195\n",
      "Iteration: 196\n",
      "Iteration: 197\n",
      "Iteration: 198\n",
      "Iteration: 199\n",
      "Iteration: 200\n",
      "Iteration: 201\n",
      "Iteration: 202\n",
      "Iteration: 203\n",
      "Iteration: 204\n",
      "Iteration: 205\n",
      "Iteration: 206\n",
      "Iteration: 207\n",
      "Iteration: 208\n",
      "Iteration: 209\n",
      "Iteration: 210\n",
      "Iteration: 211\n",
      "Iteration: 212\n",
      "Iteration: 213\n",
      "Iteration: 214\n",
      "Iteration: 215\n",
      "Iteration: 216\n",
      "Iteration: 217\n",
      "Iteration: 218\n",
      "Iteration: 219\n",
      "Iteration: 220\n",
      "Iteration: 221\n",
      "Iteration: 222\n",
      "Iteration: 223\n",
      "Iteration: 224\n",
      "Iteration: 225\n",
      "Iteration: 226\n",
      "Iteration: 227\n",
      "Iteration: 228\n",
      "Iteration: 229\n",
      "Iteration: 230\n",
      "Iteration: 231\n",
      "Iteration: 232\n",
      "Iteration: 233\n",
      "Iteration: 234\n",
      "Iteration: 235\n",
      "Iteration: 236\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(test_dataloader):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    print(\"Iteration: {}\".format(i))\n",
    "    x = data[\"x\"]\n",
    "    y = data[\"y\"]\n",
    "#     x = x.unsqueeze(1)\n",
    "    y = y.view(-1,1)\n",
    "    \n",
    "    outputs = model(x)\n",
    "    \n",
    "    y_test.append(y.detach())\n",
    "    y_test_hat.append(outputs.detach())\n",
    "#     optimizer.zero_grad()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042871031910181046"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of frag_nn.pytorch.network failed: Traceback (most recent call last):\n",
      "  File \"/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 310, in update_instances\n",
      "    if hasattr(obj, '__dict__') and not (inspect.isfunction(obj)\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat(y_test)\n",
    "y_hat = torch.cat(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2361, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2361, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recall and precission for different cutoffs\n",
    "points = []\n",
    "for cutoff in np.linspace(0, 1, 100):\n",
    "    precision = get_precision(y_hat, y, cutoff)\n",
    "    recall = get_recall(y_hat, y, cutoff)\n",
    "    points.append({\"cutoff\": cutoff,\n",
    "                   \"precision\": precision, \n",
    "                   \"recall\":recall,\n",
    "                  \"num_predicted_positives\": len(y_hat[y_hat > cutoff]),\n",
    "                  \"num_true_positives\": len(y[y_hat > cutoff][y[y_hat > cutoff] == 1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(points).set_index(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_predicted_positives</th>\n",
       "      <th>num_true_positives</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutoff</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>2361</td>\n",
       "      <td>194</td>\n",
       "      <td>0.082169</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010101</th>\n",
       "      <td>2339</td>\n",
       "      <td>194</td>\n",
       "      <td>0.082941</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.020202</th>\n",
       "      <td>2149</td>\n",
       "      <td>189</td>\n",
       "      <td>0.087948</td>\n",
       "      <td>0.974227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.030303</th>\n",
       "      <td>1884</td>\n",
       "      <td>189</td>\n",
       "      <td>0.100318</td>\n",
       "      <td>0.974227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.040404</th>\n",
       "      <td>1677</td>\n",
       "      <td>189</td>\n",
       "      <td>0.112701</td>\n",
       "      <td>0.974227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.050505</th>\n",
       "      <td>1496</td>\n",
       "      <td>177</td>\n",
       "      <td>0.118316</td>\n",
       "      <td>0.912371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.060606</th>\n",
       "      <td>1308</td>\n",
       "      <td>169</td>\n",
       "      <td>0.129205</td>\n",
       "      <td>0.871134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.070707</th>\n",
       "      <td>1161</td>\n",
       "      <td>159</td>\n",
       "      <td>0.136951</td>\n",
       "      <td>0.819588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.080808</th>\n",
       "      <td>1034</td>\n",
       "      <td>150</td>\n",
       "      <td>0.145068</td>\n",
       "      <td>0.773196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.090909</th>\n",
       "      <td>924</td>\n",
       "      <td>140</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.721649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.101010</th>\n",
       "      <td>827</td>\n",
       "      <td>138</td>\n",
       "      <td>0.166868</td>\n",
       "      <td>0.711340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.111111</th>\n",
       "      <td>741</td>\n",
       "      <td>131</td>\n",
       "      <td>0.176788</td>\n",
       "      <td>0.675258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.121212</th>\n",
       "      <td>677</td>\n",
       "      <td>121</td>\n",
       "      <td>0.178730</td>\n",
       "      <td>0.623711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.131313</th>\n",
       "      <td>623</td>\n",
       "      <td>117</td>\n",
       "      <td>0.187801</td>\n",
       "      <td>0.603093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.141414</th>\n",
       "      <td>562</td>\n",
       "      <td>109</td>\n",
       "      <td>0.193950</td>\n",
       "      <td>0.561856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.151515</th>\n",
       "      <td>489</td>\n",
       "      <td>94</td>\n",
       "      <td>0.192229</td>\n",
       "      <td>0.484536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.161616</th>\n",
       "      <td>437</td>\n",
       "      <td>88</td>\n",
       "      <td>0.201373</td>\n",
       "      <td>0.453608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.171717</th>\n",
       "      <td>391</td>\n",
       "      <td>83</td>\n",
       "      <td>0.212276</td>\n",
       "      <td>0.427835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.181818</th>\n",
       "      <td>351</td>\n",
       "      <td>75</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.386598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.191919</th>\n",
       "      <td>305</td>\n",
       "      <td>66</td>\n",
       "      <td>0.216393</td>\n",
       "      <td>0.340206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.202020</th>\n",
       "      <td>272</td>\n",
       "      <td>59</td>\n",
       "      <td>0.216912</td>\n",
       "      <td>0.304124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.212121</th>\n",
       "      <td>242</td>\n",
       "      <td>51</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.262887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.222222</th>\n",
       "      <td>206</td>\n",
       "      <td>43</td>\n",
       "      <td>0.208738</td>\n",
       "      <td>0.221649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.232323</th>\n",
       "      <td>177</td>\n",
       "      <td>38</td>\n",
       "      <td>0.214689</td>\n",
       "      <td>0.195876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.242424</th>\n",
       "      <td>149</td>\n",
       "      <td>32</td>\n",
       "      <td>0.214765</td>\n",
       "      <td>0.164948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.252525</th>\n",
       "      <td>123</td>\n",
       "      <td>24</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.123711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.262626</th>\n",
       "      <td>95</td>\n",
       "      <td>17</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.087629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.272727</th>\n",
       "      <td>72</td>\n",
       "      <td>16</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.082474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.282828</th>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.061856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.292929</th>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.041237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.707071</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.717172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.727273</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.737374</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.747475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.757576</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.767677</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.777778</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.787879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.797980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.808081</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.818182</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.828283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.838384</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.848485</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.858586</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.868687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.878788</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.888889</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.898990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.909091</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.919192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.929293</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.939394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.949495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.959596</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.969697</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.979798</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.989899</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_predicted_positives  num_true_positives  precision    recall\n",
       "cutoff                                                                    \n",
       "0.000000                     2361                 194   0.082169  1.000000\n",
       "0.010101                     2339                 194   0.082941  1.000000\n",
       "0.020202                     2149                 189   0.087948  0.974227\n",
       "0.030303                     1884                 189   0.100318  0.974227\n",
       "0.040404                     1677                 189   0.112701  0.974227\n",
       "0.050505                     1496                 177   0.118316  0.912371\n",
       "0.060606                     1308                 169   0.129205  0.871134\n",
       "0.070707                     1161                 159   0.136951  0.819588\n",
       "0.080808                     1034                 150   0.145068  0.773196\n",
       "0.090909                      924                 140   0.151515  0.721649\n",
       "0.101010                      827                 138   0.166868  0.711340\n",
       "0.111111                      741                 131   0.176788  0.675258\n",
       "0.121212                      677                 121   0.178730  0.623711\n",
       "0.131313                      623                 117   0.187801  0.603093\n",
       "0.141414                      562                 109   0.193950  0.561856\n",
       "0.151515                      489                  94   0.192229  0.484536\n",
       "0.161616                      437                  88   0.201373  0.453608\n",
       "0.171717                      391                  83   0.212276  0.427835\n",
       "0.181818                      351                  75   0.213675  0.386598\n",
       "0.191919                      305                  66   0.216393  0.340206\n",
       "0.202020                      272                  59   0.216912  0.304124\n",
       "0.212121                      242                  51   0.210744  0.262887\n",
       "0.222222                      206                  43   0.208738  0.221649\n",
       "0.232323                      177                  38   0.214689  0.195876\n",
       "0.242424                      149                  32   0.214765  0.164948\n",
       "0.252525                      123                  24   0.195122  0.123711\n",
       "0.262626                       95                  17   0.178947  0.087629\n",
       "0.272727                       72                  16   0.222222  0.082474\n",
       "0.282828                       50                  12   0.240000  0.061856\n",
       "0.292929                       29                   8   0.275862  0.041237\n",
       "...                           ...                 ...        ...       ...\n",
       "0.707071                        0                   0   1.000000  0.000000\n",
       "0.717172                        0                   0   1.000000  0.000000\n",
       "0.727273                        0                   0   1.000000  0.000000\n",
       "0.737374                        0                   0   1.000000  0.000000\n",
       "0.747475                        0                   0   1.000000  0.000000\n",
       "0.757576                        0                   0   1.000000  0.000000\n",
       "0.767677                        0                   0   1.000000  0.000000\n",
       "0.777778                        0                   0   1.000000  0.000000\n",
       "0.787879                        0                   0   1.000000  0.000000\n",
       "0.797980                        0                   0   1.000000  0.000000\n",
       "0.808081                        0                   0   1.000000  0.000000\n",
       "0.818182                        0                   0   1.000000  0.000000\n",
       "0.828283                        0                   0   1.000000  0.000000\n",
       "0.838384                        0                   0   1.000000  0.000000\n",
       "0.848485                        0                   0   1.000000  0.000000\n",
       "0.858586                        0                   0   1.000000  0.000000\n",
       "0.868687                        0                   0   1.000000  0.000000\n",
       "0.878788                        0                   0   1.000000  0.000000\n",
       "0.888889                        0                   0   1.000000  0.000000\n",
       "0.898990                        0                   0   1.000000  0.000000\n",
       "0.909091                        0                   0   1.000000  0.000000\n",
       "0.919192                        0                   0   1.000000  0.000000\n",
       "0.929293                        0                   0   1.000000  0.000000\n",
       "0.939394                        0                   0   1.000000  0.000000\n",
       "0.949495                        0                   0   1.000000  0.000000\n",
       "0.959596                        0                   0   1.000000  0.000000\n",
       "0.969697                        0                   0   1.000000  0.000000\n",
       "0.979798                        0                   0   1.000000  0.000000\n",
       "0.989899                        0                   0   1.000000  0.000000\n",
       "1.000000                        0                   0   1.000000  0.000000\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f02df3efda0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=\"recall\",\n",
    "               y=\"precision\",\n",
    "               data=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f02912f9320>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=\"recall\",\n",
    "               y=\"precision\",\n",
    "               data=stats,\n",
    "            estimator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08216857263871241"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.iloc[0].num_true_positives / stats.iloc[0].num_predicted_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014759093505998857"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_precision = len(events_test[events_test[\"Ligand Confidence\"] == \"High\"]) / len(events_train)\n",
    "base_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate - Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_test_hat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_dataloader):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    print(\"Iteration: {}\".format(i))\n",
    "    x = data[\"x\"]\n",
    "    y = data[\"y\"]\n",
    "#     x = x.unsqueeze(1)\n",
    "    y = y.view(-1,1)\n",
    "    \n",
    "    outputs = model(x)\n",
    "    \n",
    "    y_test.append(y.detach())\n",
    "    y_test_hat.append(outputs.detach())\n",
    "#     optimizer.zero_grad()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat(y_test)\n",
    "y_hat = torch.cat(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recall and precission for different cutoffs\n",
    "points = []\n",
    "for cutoff in np.linspace(0, 1, 50):\n",
    "    precision = get_precision(y_hat, y, cutoff)\n",
    "    recall = get_recall(y_hat, y, cutoff)\n",
    "    points.append({\"cutoff\": cutoff,\n",
    "                   \"precision\": precision, \n",
    "                   \"recall\":recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(points).set_index(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"recall\",\n",
    "               y=\"precision\",\n",
    "               data=stats,\n",
    "            estimator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"recall\",\n",
    "               y=\"precision\",\n",
    "               data=stats,\n",
    "            estimator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_precision = len(events_train[events_train[\"ligand_confidence_inspect\"] == \"High\"]) / len(events_train)\n",
    "base_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_params.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(model, optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
