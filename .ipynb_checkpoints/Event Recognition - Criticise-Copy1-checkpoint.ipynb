{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import configparser\n",
    "import pathlib as p\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clipper_python as clipper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frag_nn.pytorch.network import GNINA_regressor, GNINA_regressor_v2, GNINA_regressor_v3, GNINA_regressor_v4, GNINA_regressor_v5, GNINA_regressor_v6, GNINA_regressor_v7, GNINA_regressor_v8\n",
    "from frag_nn.data import XChemData\n",
    "from frag_nn.pytorch.network import ClassifierV3\n",
    "from frag_nn.pytorch.dataset import EventDataset\n",
    "from frag_nn.pytorch.dataset import OrthogonalGrid\n",
    "from frag_nn.pytorch.dataset import GetRandomisedLocation, GetRandomisedRotation\n",
    "from frag_nn.pytorch.dataset import GetAnnotationClassifier, GetDataRefMoveZ\n",
    "\n",
    "from frag_nn.pytorch.dataset import XChemDataset\n",
    "import frag_nn.constants as c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/dls/science/groups/i04-1/conor_dev/pandda_nn/frag_nn/params.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/dls/science/groups/i04-1/conor_dev/pandda_nn/frag_nn/params.ini']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.read(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_conf = conf[c.x_chem_database]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 48\n",
    "grid_step = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = \"classifier\"\n",
    "network_version = 3\n",
    "dataset_version = 3\n",
    "train = \"cluster\"\n",
    "transforms = \"rottrans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_dir = \"/dls/science/groups/i04-1/conor_dev/pandda_nn/\"\n",
    "state_dict_file = state_dict_dir + \"model_params_{}_{}_{}_{}_{}_{}_{}.pt\".format(grid_size,\n",
    "                                                                                  grid_step,\n",
    "                                                                                  network_type,\n",
    "                                                                                  network_version,\n",
    "                                                                                  dataset_version,\n",
    "                                                                                  train,\n",
    "                                                                                  transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chem_dataset = XChemData(host=ds_conf[c.db_host], \n",
    "                         port=ds_conf[c.db_port], \n",
    "                         database=ds_conf[c.db_database], \n",
    "                         user=ds_conf[c.db_user], \n",
    "                         password=ds_conf[c.db_password])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = x_chem_dataset.get_database(\"pandda_event\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get accessible events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessible_events_list = []\n",
    "\n",
    "for pth in events[\"pandda_input_mtz\"]:\n",
    "    try:\n",
    "        if p.Path(pth).exists():\n",
    "            accessible_events_list.append(True)\n",
    "        else:\n",
    "            accessible_events_list.append(False)\n",
    "            \n",
    "    except PermissionError as e:\n",
    "        accessible_events_list.append(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessible_events_mask = np.array(accessible_events_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessible_events = events[accessible_events_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = np.random.rand(len(accessible_events)) < 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n"
     ]
    }
   ],
   "source": [
    "events_train = accessible_events[split]#\n",
    "print(len(events_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n"
     ]
    }
   ],
   "source": [
    "events_test = accessible_events[~split]\n",
    "print(len(events_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dls/science/groups/i04-1/conor_dev/anaconda/envs/env_pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "events_train = pd.read_csv(\"new_events_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_test = pd.read_csv(\"new_events_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = XChemDataset(events_train,\n",
    "#                               mode=\"RefMovev2\",\n",
    "#                  grid_size=grid_size,\n",
    "#                  grid_step=grid_step,\n",
    "#                             replace_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= OrthogonalGrid(grid_size, \n",
    "                     grid_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = EventDataset(events=events_test,\n",
    "                             transforms_record=[],\n",
    "                             get_annotation=GetAnnotationClassifier(),\n",
    "                             get_data=GetDataRefMoveZ(grid)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_dataset[np.random.randint(len(test_dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 48, 48, 48)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = x_t.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 48, 48, 48])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"annotation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = dataset_train[10][\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_2 = dataset_train[10][\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_np_slice_2d = x[:, :, int(x.shape[2]/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_np_slice_2d_2 = x_2[:, :, int(x.shape[2]/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_np_slice_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_np_slice_2d_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = torch.utils.data.DataLoader(dataset_train,\n",
    "#                                          batch_size=10, \n",
    "#                                          shuffle=True,\n",
    "#                                          num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                         batch_size=10, \n",
    "                                         shuffle=True,\n",
    "                                         num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierV3(32,\n",
    "                        grid_dimension=grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(state_dict_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierV3(\n",
      "  (conv_1): Sequential(\n",
      "    (0): Conv3d(3, 32, kernel_size=(9, 9, 9), stride=(1, 1, 1), padding=(4, 4, 4))\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer_1): ResidualLayerWithDrop(\n",
      "    (conv_1): Sequential(\n",
      "      (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (res_1): ResidualBlock(\n",
      "      (conv_1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (drop): Dropout3d(p=0.1)\n",
      "    (mp): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (layer_2): ResidualLayerWithDrop(\n",
      "    (conv_1): Sequential(\n",
      "      (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (res_1): ResidualBlock(\n",
      "      (conv_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (drop): Dropout3d(p=0.1)\n",
      "    (mp): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (layer_3): ResidualLayerWithDrop(\n",
      "    (conv_1): Sequential(\n",
      "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (res_1): ResidualBlock(\n",
      "      (conv_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (drop): Dropout3d(p=0.1)\n",
      "    (mp): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=6912, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (act): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision - Recall functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(y_hat, y, cutoff):\n",
    "    \n",
    "    positives_hat_mask = (y_hat > cutoff)\n",
    "    negatives_hat_mask = (y_hat <= cutoff)\n",
    "    \n",
    "    positives_mask = (y == 1)\n",
    "    negatives_mask = (y == 0)\n",
    "\n",
    "    true_positives = np.count_nonzero(positives_hat_mask[positives_mask])\n",
    "    false_positives = np.count_nonzero(positives_hat_mask[negatives_mask])\n",
    "    \n",
    "    total_predicted_positives = true_positives + false_positives\n",
    "    \n",
    "    if total_predicted_positives == 0:\n",
    "        return 1\n",
    "    \n",
    "    precision = true_positives / total_predicted_positives\n",
    "    \n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(y_hat, y, cutoff):\n",
    "    positives_hat_mask = (y_hat > cutoff)\n",
    "    negatives_hat_mask = (y_hat <= cutoff)\n",
    "\n",
    "    positives_mask = (y == 1)\n",
    "    negatives_mask = (y == 0)\n",
    "\n",
    "    true_positives = np.count_nonzero(positives_hat_mask[positives_mask])\n",
    "    false_negatives = np.count_nonzero(negatives_hat_mask[positives_mask])    \n",
    "\n",
    "    total_positives = (true_positives + false_negatives)\n",
    "    \n",
    "    if total_positives == 0:\n",
    "        return 0\n",
    "    \n",
    "    recall = true_positives / total_positives\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate - Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_test_hat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_dataloader):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    print(\"Iteration: {}\".format(i))\n",
    "    x = data[\"data\"]\n",
    "    y = data[\"annotation\"]\n",
    "#     x = x.unsqueeze(1)\n",
    "    y = y.view(-1,2)\n",
    "    \n",
    "    outputs = model(x)\n",
    "    \n",
    "    y_test.append(y.detach())\n",
    "    y_test_hat.append(outputs.detach())\n",
    "#     optimizer.zero_grad()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat(y_test)[:,1]\n",
    "y_hat = torch.cat(y_test_hat)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recall and precission for different cutoffs\n",
    "points = []\n",
    "for cutoff in np.linspace(0, 1, 100):\n",
    "    precision = get_precision(y_hat, y, cutoff)\n",
    "    recall = get_recall(y_hat, y, cutoff)\n",
    "    points.append({\"cutoff\": cutoff,\n",
    "                   \"precision\": precision, \n",
    "                   \"recall\":recall,\n",
    "                  \"num_predicted_positives\": len(y_hat[y_hat > cutoff]),\n",
    "                  \"num_true_positives\": len(y[y_hat > cutoff][y[y_hat > cutoff] == 1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(points).set_index(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"recall\",\n",
    "               y=\"precision\",\n",
    "               data=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"recall\",\n",
    "               y=\"precision\",\n",
    "               data=stats,\n",
    "            estimator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.iloc[0].num_true_positives / stats.iloc[0].num_predicted_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_precision = len(events_test[events_test[\"Ligand Confidence\"] == \"High\"]) / len(events_train)\n",
    "base_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate - Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_test_hat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_dataloader):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    print(\"Iteration: {}\".format(i))\n",
    "    x = data[\"x\"]\n",
    "    y = data[\"y\"]\n",
    "#     x = x.unsqueeze(1)\n",
    "    y = y.view(-1,1)\n",
    "    \n",
    "    outputs = model(x)\n",
    "    \n",
    "    y_test.append(y.detach())\n",
    "    y_test_hat.append(outputs.detach())\n",
    "#     optimizer.zero_grad()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat(y_test)\n",
    "y_hat = torch.cat(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get recall and precission for different cutoffs\n",
    "points = []\n",
    "for cutoff in np.linspace(0, 1, 50):\n",
    "    precision = get_precision(y_hat, y, cutoff)\n",
    "    recall = get_recall(y_hat, y, cutoff)\n",
    "    points.append({\"cutoff\": cutoff,\n",
    "                   \"precision\": precision, \n",
    "                   \"recall\":recall})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(points).set_index(\"cutoff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"recall\",\n",
    "               y=\"precision\",\n",
    "               data=stats,\n",
    "            estimator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"recall\",\n",
    "               y=\"precision\",\n",
    "               data=stats,\n",
    "            estimator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_precision = len(events_train[events_train[\"ligand_confidence_inspect\"] == \"High\"]) / len(events_train)\n",
    "base_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_params.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_32.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(model, optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
